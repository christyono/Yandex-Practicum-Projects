{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Open the file and study the general information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      "id         100000 non-null object\n",
      "f0         100000 non-null float64\n",
      "f1         100000 non-null float64\n",
      "f2         100000 non-null float64\n",
      "product    100000 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "      id        f0        f1        f2     product\n",
      "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
      "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
      "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
      "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
      "4  Xdl7t  1.988431  0.155413  4.751769  154.036647\n"
     ]
    }
   ],
   "source": [
    "data_0 = pd.read_csv('/datasets/geo_data_0.csv')\n",
    "\n",
    "print(data_0.info())\n",
    "print(data_0.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      "id         100000 non-null object\n",
      "f0         100000 non-null float64\n",
      "f1         100000 non-null float64\n",
      "f2         100000 non-null float64\n",
      "product    100000 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "      id         f0         f1        f2     product\n",
      "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
      "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
      "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
      "4  AHL4O  12.702195  -8.147433  5.004363  134.766305\n"
     ]
    }
   ],
   "source": [
    "data_1 = pd.read_csv('/datasets/geo_data_1.csv')\n",
    "\n",
    "print(data_1.info())\n",
    "print(data_1.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      "id         100000 non-null object\n",
      "f0         100000 non-null float64\n",
      "f1         100000 non-null float64\n",
      "f2         100000 non-null float64\n",
      "product    100000 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "      id        f0        f1        f2     product\n",
      "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
      "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
      "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
      "4  WPMUX -0.515993  1.716266  5.899011  149.600746\n"
     ]
    }
   ],
   "source": [
    "data_2 = pd.read_csv('/datasets/geo_data_2.csv')\n",
    "\n",
    "print(data_2.info())\n",
    "print(data_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The info and head methods show that there aren't missing variables in any columns, and the data types are all correct. Our goal is to compare the data for the three different regions and select the region with the highest profit margin, analyzing the potential profit and risks using bootstrapping.\n",
    "\n",
    "To do so, we'll first need to create models for each data set and compare them. Our target is product, while our features are f0, f1, and f2.\n",
    "\n",
    "We need to do two things to prepare our data:\n",
    "1. Remove columns that don't contribute to our model - in this case, it's the 'id' column\n",
    "2. Split our data into training and validation sets with a 75:25 ratio\n",
    "3. Standardize numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the process of data preparation is the same for all models, let's first create a function for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             f0        f1        f2\n",
      "27212 -0.544828  1.390264 -0.094959\n",
      "7866   1.455912 -0.480422  1.209567\n",
      "62041  0.260460  0.825069 -0.204865\n",
      "70185 -1.837105  0.010321 -0.147634\n",
      "82230 -1.299243  0.987558  1.273181\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\") #filter warnings created by standardizing data on copied dataframe\n",
    "\n",
    "#takes a data set and returns the training and validation sets for the data\n",
    "def prep_data(data):\n",
    "    \n",
    "    #drop id\n",
    "    data = data.drop(['id'], axis = 1)\n",
    "    \n",
    "    #get features and target\n",
    "    features = data.drop(['product'], axis=1)\n",
    "    target = data['product']\n",
    "    \n",
    "    #split data into training and validation sets\n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "        features, target, test_size=0.25, random_state=12345)\n",
    "    \n",
    "    #standardize\n",
    "    scaler = StandardScaler()\n",
    "    numeric = ['f0','f1','f2']\n",
    "    \n",
    "    scaler.fit(features_train[numeric])\n",
    "    \n",
    "    features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "    features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "    \n",
    "    #return features and target for both training and validation sets\n",
    "    return features_train, features_valid, target_train, target_valid\n",
    "\n",
    "#call prep_data function for all data sets\n",
    "d0_features_train, d0_features_valid, d0_target_train, d0_target_valid = prep_data(data_0)\n",
    "\n",
    "d1_features_train, d1_features_valid, d1_target_train, d1_target_valid = prep_data(data_1)\n",
    "\n",
    "d2_features_train, d2_features_valid, d2_target_train, d2_target_valid = prep_data(data_2)\n",
    "\n",
    "#check\n",
    "print(d0_features_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to repeat the same steps again for all three data sets, so we'll create another method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average volume of predicted reserves for data set 0: 92.59256778438038\n",
      "Average volume of predicted reserves for data set 1: 68.728546895446\n",
      "Average volume of predicted reserves for data set 2: 94.96504596800489\n",
      "Data set 0 RMSE: 37.5794217150813\n",
      "Data set 1 RMSE: 0.8930992867756158\n",
      "Data set 2 RMSE: 40.02970873393434\n"
     ]
    }
   ],
   "source": [
    "def get_prediction(features_train, features_valid, target_train):\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    \n",
    "    return predicted_valid\n",
    "\n",
    "d0_prediction = pd.Series(get_prediction(d0_features_train, d0_features_valid, d0_target_train))\n",
    "d1_prediction = pd.Series(get_prediction(d1_features_train, d1_features_valid, d1_target_train))\n",
    "d2_prediction = pd.Series(get_prediction(d2_features_train, d2_features_valid, d2_target_train))\n",
    "\n",
    "print(\"Average volume of predicted reserves for data set 0:\", d0_prediction.mean())\n",
    "print(\"Average volume of predicted reserves for data set 1:\", d1_prediction.mean())\n",
    "print(\"Average volume of predicted reserves for data set 2:\", d2_prediction.mean())\n",
    "\n",
    "print(\"Data set 0 RMSE:\", mean_squared_error(d0_target_valid, d0_prediction)**0.5)\n",
    "print(\"Data set 1 RMSE:\", mean_squared_error(d1_target_valid, d1_prediction)**0.5)\n",
    "print(\"Data set 2 RMSE:\", mean_squared_error(d2_target_valid, d2_prediction)**0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we go by average volume of predicted reserves, the obvious choice seems to be either the locations associated with data set 0 and 3. However, the root mean squared error for both of those sets is significantly higher than the RMSE for data set 1, meaning that the potential for a much lower profit than expected lies in those same locations. We'll have to further study the data to come to a better conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Prepare for profit calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The budget for development of 200 oil wells is 100 USD million.\n",
    "\n",
    "One barrel of raw materials brings 4.5 USD of revenue The revenue from one unit of product is 4,500 dollars (volume of reserves is in thousand barrels).\"\n",
    "\n",
    "Considering these points, we'll **calculate the volume of reserves sufficient for developing a new well without losses**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume of reserves(by the thousand) sufficient for developing a new well without losses: 111.11111111111111\n"
     ]
    }
   ],
   "source": [
    "WELLS = 200\n",
    "BUDGET= 100000000\n",
    "USD_PER_BARREL = 4.5\n",
    "\n",
    "budget_per_well = BUDGET/WELLS\n",
    "\n",
    "products_ROI = (budget_per_well/USD_PER_BARREL) / 1000 #our target products is calculated by the thousand\n",
    "\n",
    "print(\"Volume of reserves(by the thousand) sufficient for developing a new well without losses:\",products_ROI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By finding the average budget required for a single well(budget/well), and dividing that by the revenue from one unit of product(4.5\\*1000), we get the volume amount necessary for our ROI.\n",
    "\n",
    "If we go by merely the average volume of predicted reserves for each region, none of the locations would be profitable, since we don't meet the minimum required reserves to break even. This means **we have to selectively choose locations in each region where the volume of predicted reserves is greater than the average for its region**.\n",
    "\n",
    "Let's define a function to calculate profits, and utilize this function for each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total profit of predicted top 200 wells of data set 0: $33208260.43 USD\n",
      "Total profit of predicted top 200 wells of data set 1: $24150866.97 USD\n",
      "Total profit of predicted top 200 wells of data set 2: $27103499.64 USD\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "our method takes 2 parameters - the target and predicted target\n",
    "It will return the total profit for that particular set.\n",
    "'''\n",
    "def calculate_profit(target, predictions):\n",
    "    #sort predicted target data\n",
    "    \n",
    "    sorted_probs = predictions.sort_values(ascending=False)\n",
    "    #save wells with highest predicted values, and retrieve the true values for those wells\n",
    "    selected = target[sorted_probs.index][:200]\n",
    "\n",
    "    #calculate revenue\n",
    "    revenue = usd_per_barrel*1000*selected.sum()\n",
    "    \n",
    "    #return total profit\n",
    "    return round(revenue - budget, 2)\n",
    "\n",
    "d0_target_valid = d0_target_valid.reset_index(drop=True)\n",
    "d1_target_valid = d1_target_valid.reset_index(drop=True)\n",
    "d2_target_valid = d2_target_valid.reset_index(drop=True)\n",
    "\n",
    "print(\"Total profit of predicted top 200 wells of data set 0: ${} USD\".format(calculate_profit(d0_target_valid, d0_prediction)))\n",
    "print(\"Total profit of predicted top 200 wells of data set 1: ${} USD\".format(calculate_profit(d1_target_valid, d1_prediction)))\n",
    "print(\"Total profit of predicted top 200 wells of data set 2: ${} USD\".format(calculate_profit(d2_target_valid, d2_prediction)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our calculations shows that the total profit of the top 200 predicted wells is highest for **data set 0**. If we were to base our decision from the top predictions, this would be our choice - however, realistically, our wells will not all be the most profitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Calculate risks and profit for each region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use bootstrapping to determine the distribution of profits, and utilize the distribution of profits to determine the best region to build wells.\n",
    "\n",
    "Let's define a method to use for the different data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 0:\n",
      "Average profit: $4259385.26927 USD\n",
      "95% confidence interval: (-1020900.94925,9479763.53575)\n",
      "Risk of loss: 6%\n",
      "\n",
      "Region 1\n",
      "Average profit: $5182594.936989999 USD\n",
      "95% confidence interval: (1281232.31,9536129.818999998)\n",
      "Risk of loss: 0%\n",
      "\n",
      "Region 2\n",
      "Average profit: $4201940.0534500005 USD\n",
      "95% confidence interval: (-1158526.08925,9896299.40225)\n",
      "Risk of loss: 6%\n"
     ]
    }
   ],
   "source": [
    "state = RandomState(12345)\n",
    "\n",
    "def calculate_risks_and_profit(target, prediction):\n",
    "    target = target.reset_index(drop=True)\n",
    "    values = []\n",
    "    negatives = 0\n",
    "    for i in range(1000):\n",
    "        predicted_subsample = prediction.sample(n=500, replace=True, random_state=state)\n",
    "        target_subsample = target[predicted_subsample.index]\n",
    "        profit = calculate_profit(target_subsample, predicted_subsample)\n",
    "        values.append(profit)\n",
    "        if profit < 0:\n",
    "            negatives += 1\n",
    "        \n",
    "    values = pd.Series(values)\n",
    "    \n",
    "    mean = values.mean()\n",
    "\n",
    "    lower = values.quantile(.025)\n",
    "    upper = values.quantile(.975)\n",
    "    \n",
    "    risk_of_loss = negatives/1000\n",
    "    \n",
    "    print(\"Average profit: ${} USD\".format(mean))\n",
    "    print(\"95% confidence interval: ({},{})\".format(lower, upper))\n",
    "    print(\"Risk of loss: {0:.0%}\".format(risk_of_loss))\n",
    "\n",
    "print(\"Region 0:\")\n",
    "calculate_risks_and_profit(d0_target_valid, d0_prediction)\n",
    "\n",
    "print(\"\\nRegion 1\")\n",
    "calculate_risks_and_profit(d1_target_valid, d1_prediction)\n",
    "\n",
    "print(\"\\nRegion 2\")\n",
    "calculate_risks_and_profit(d2_target_valid, d2_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our studies, **Region 1** should be our choice for developing new wells. The variance of average profit in region 0 and region 2 is much greater than region 1, and the risk of loss is significant, at a 6% probability of not making a profit. Additionally, the highest average profit lies in region 1, making it a safe choice to develop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
